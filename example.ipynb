{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d16748c-90b8-4f4f-a1fa-a3081eef315e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package machado to\n",
      "[nltk_data]     C:\\Users\\fernandesr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package machado is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import nltk\n",
    "nltk_id = 'machado'\n",
    "nltk.download(nltk_id)\n",
    "from nltk.corpus import machado\n",
    "\n",
    "from model import GPTConfig, GPT\n",
    "from train import get_batch, estimate_loss\n",
    "from data.char_level import CharEncDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fce467-05d2-4d8a-a2ad-99d6b0d72e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read Machado de Assis corpora and perform basic cleaning \n",
    "text = machado.raw()\n",
    "text = re.sub('[^A-Za-zÀ-ÖØ-öø-ÿ.!?\\\\\\n]', ' ',text)\n",
    "text = re.sub(' +', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c082dc4-6e8f-4445-a77b-c4ebf067a4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  14413687\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "482ac144-5241-4f07-82a5-c0055a523381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as tranças loiras. A moça em questão deve ser\n",
      "vaporosa e ideal como uma criação de Shakespeare deve ser o contraste do roastbeef\n",
      "britânico com que se alimenta a liberdade do Reino Unido. Uma tal Miss\n",
      "Dollar deve ter o poeta Tennyson de cor e ler Lamartine no original se\n",
      "souber o português deve deliciar se com a leitura dos sonetos de Camões ou os Cantos\n",
      "de Gonçalves Dias. O chá e o leite devem ser a alimentação de semelhante\n",
      "criatura adicionando se lhe alguns confeitos e biscoitos para acudir às\n",
      "urgências do estômago. A sua fala deve ser um murmúrio de harpa eólia o seu\n",
      "amor um desmaio a sua vida uma contemplação a sua morte um suspiro.\n",
      "\n",
      "A figura é poética mas não é a da\n",
      "heroína do romance.\n",
      "\n",
      "Suponhamos que o leitor não é dado a\n",
      "estes devaneios e melancolias nesse caso imagina uma Miss Dollar totalmente\n",
      "diferente da outra. Desta vez será uma robusta americana vertendo sangue pelas\n",
      "faces formas arredondadas olhos vivos e ardentes mulher feita refeita e\n",
      "perfeita. Amiga da boa mesa e do bo\n"
     ]
    }
   ],
   "source": [
    "print(text[1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37248f5a-26c1-4ce4-bfaf-6fc445a2bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      " !.?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÀÁÂÃÇÈÉÊËÍÓÔÕÚÛÜàáâãäçèéêëìíîïñòóôõöùúûü\n",
      "vocab length:  97\n"
     ]
    }
   ],
   "source": [
    "# the tokenizer will transform characters into numbers\n",
    "\n",
    "tokenizer = CharEncDec(text)\n",
    "print('vocab: ', ''.join(tokenizer.chars))\n",
    "print('vocab length: ', tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d0b0ad-884c-4873-bc22-0558b843ea56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 45, 44, 50, 45, 1, 7, 45, 44, 50, 45, 49, 1, 10, 42, 51, 43, 39, 44, 35, 44, 49, 35, 49, 1, 0, 0, 7, 45, 44, 50, 45, 49, 1, 10, 42, 51, 43, 39, 44, 35, 44, 49, 35, 49, 0, 0, 24, 35, 54, 50, 45, 1, 36, 45, 44, 50, 35, 1, 0, 0, 19, 32, 48, 31, 1, 7, 45, 43, 46, 42, 35, 50, 31, 1, 17, 31, 33, 38, 31, 34, 45, 1, 34, 35, 1, 5, 49, 49, 39, 49, 1, 52, 45, 42, 3, 1, 13, 13, 1, 0, 0, 22, 39, 45, 1, 34, 35, 1, 14, 31, 44, 35, 39, 48, 45, 1, 18, 45, 52, 31, 1, 5, 37, 51, 39, 42, 31, 48, 1, 3, 0, 0, 20, 51, 32, 42, 39, 33, 31, 34, 45, 1, 45, 48, 39, 37, 39, 44, 31, 42, 43, 35, 44, 50, 35, 1, 46, 35, 42, 31, 0, 9, 34, 39, 50, 45, 48, 31, 1, 11, 31, 48, 44, 39, 35, 48, 1, 22, 39, 45, 1, 34, 35, 1, 14, 31, 44, 35, 39, 48, 45, 1, 35, 43, 1, 3, 0, 0, 66, 18, 8, 13, 7, 9, 0, 0, 17, 13, 23, 23, 1, 8, 19, 16, 16, 5, 22, 0, 0, 16, 25, 66, 23, 0, 23, 19, 5, 22, 9, 23, 0, 0, 5, 1, 17, 25, 16, 12, 9, 22, 1, 8, 9, 0, 20, 22, 9, 24, 19, 0, 0, 19, 0, 23, 9, 11, 22, 9, 8, 19, 1, 8, 9, 1, 5, 25, 11, 25, 23, 24, 5, 0, 0, 7, 19, 18, 10, 13, 23, 23, 69, 9, 23, 1, 8, 9, 1, 25, 17, 5, 1, 26, 13, 70, 26, 5, 1, 17, 19, 61, 5, 0, 0, 16, 13, 18, 12, 5, 0, 22, 9, 24, 5, 1, 9, 1, 16, 13, 18, 12, 5, 1, 7, 25, 22, 26, 5, 0, 0, 10, 22, 9, 13, 0, 23, 13, 17, 60, 19, 0, 0, 17, 13, 23, 23, 0, 8, 19, 16, 16, 5, 22, 0, 0, 66, 18, 8, 13, 7, 9, 0, 0, 7, 31, 46, 84, 50, 51, 42, 45, 1, 20, 48, 39, 43, 35, 39, 48, 45, 0, 0, 7, 31, 46, 84, 50, 51, 42, 45, 1, 13, 13, 0, 0, 7, 31, 46, 84, 50, 51, 42, 45, 1, 39, 39, 39, 0, 0, 7, 31, 46, 84, 50, 51, 42, 45, 1, 39, 52, 0, 0, 7, 31, 46, 84, 50, 51, 42, 45, 1, 52, 0, 0, 7, 31, 46, 84, 50, 51, 42, 45, 1, 52, 13, 0, 0, 7, 31, 46, 84, 50, 51, 42, 45, 1, 52, 13, 13, 0, 0, 7, 5, 20, 66, 24, 25, 16, 19, 1, 26, 13, 13, 13, 0, 0, 7, 5, 20, 66, 24, 25, 16, 19, 1, 20, 22, 13, 17, 9, 13, 22, 19, 0, 0, 9, 48, 31, 1, 33]\n",
      "Conto Contos Fluminenses \n",
      "\n",
      "Contos Fluminenses\n",
      "\n",
      "Texto fonte \n",
      "\n",
      "Obra Completa Machado de Assis vol. II \n",
      "\n",
      "Rio de Janeiro Nova Aguilar .\n",
      "\n",
      "Publicado originalmente pela\n",
      "Editora Garnier Rio de Janeiro em .\n",
      "\n",
      "ÍNDICE\n",
      "\n",
      "MISS DOLLAR\n",
      "\n",
      "LUÍS\n",
      "SOARES\n",
      "\n",
      "A MULHER DE\n",
      "PRETO\n",
      "\n",
      "O\n",
      "SEGREDO DE AUGUSTA\n",
      "\n",
      "CONFISSÕES DE UMA VIÚVA MOÇA\n",
      "\n",
      "LINHA\n",
      "RETA E LINHA CURVA\n",
      "\n",
      "FREI\n",
      "SIMÃO\n",
      "\n",
      "MISS\n",
      "DOLLAR\n",
      "\n",
      "ÍNDICE\n",
      "\n",
      "Capítulo Primeiro\n",
      "\n",
      "Capítulo II\n",
      "\n",
      "Capítulo iii\n",
      "\n",
      "Capítulo iv\n",
      "\n",
      "Capítulo v\n",
      "\n",
      "Capítulo vI\n",
      "\n",
      "Capítulo vII\n",
      "\n",
      "CAPÍTULO VIII\n",
      "\n",
      "CAPÍTULO PRIMEIRO\n",
      "\n",
      "Era c\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers so we can train a Transformer\n",
    "\n",
    "print(tokenizer.encode(text[:500]))\n",
    "print(tokenizer.decode(tokenizer.encode(text[:500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8168b8-83ae-4499-857c-e0d95d5b3e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# passing data to pytorch to train the NN\n",
    "\n",
    "data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbe64ef-214b-4e43-b583-7021f8fe5643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 97])\n",
      "tensor(4.6934, grad_fn=<NllLossBackward0>)\n",
      "generation without training:  \n",
      "nNWõirrÕIwJjùTÛKiÈìÓQaËÍnoiÊvMÀckì!yÍxÀytÓáQSrIVszQv?çöÔÔ.úzfLÓwBMÕeRèàAéFÇoõUòGíbóKòbZNsDÃÀuvzbIFõw\n",
      "Num params:  44193\n"
     ]
    }
   ],
   "source": [
    "config = GPTConfig()\n",
    "\n",
    "block_size = 128 #the maximum context we can have to generate the next char\n",
    "config.block_size = block_size\n",
    "config.vocab_size = tokenizer.vocab_size\n",
    "config.n_layer = 3 #how many attention blocks we want to have \n",
    "config.n_head = 4 #number of attention heads\n",
    "config.n_embd = 32 #embedding dim\n",
    "config.dropout = 0.1 #regularization\n",
    "\n",
    "\n",
    "batch_size = 32 # how many independent sequences will we process in parallel\n",
    "max_iters = 15000 # iterations of gradient descent, the higher the longer it takes\n",
    "eval_interval = 500 # interval to report train/val loss\n",
    "learning_rate = 1e-2\n",
    "eval_iters = 200 # number of batches used to calc train/val loss\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = GPT(config)\n",
    "m = model.to(device)\n",
    "xb, yb = get_batch(train_data, batch_size, block_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print('generation without training: ', tokenizer.decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))\n",
    "print('Num params: ', m.get_num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a6f1479-5791-4987-92ba-0a23b622d1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b41bfc1ed943798802e5d6f3db3aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.6947, val loss 4.7074\n",
      "step 500: train loss 2.2847, val loss 2.3682\n",
      "step 1000: train loss 2.1001, val loss 2.2139\n",
      "step 1500: train loss 2.0080, val loss 2.1214\n",
      "step 2000: train loss 1.9538, val loss 2.0791\n",
      "step 2500: train loss 1.9302, val loss 2.0506\n",
      "step 3000: train loss 1.9135, val loss 2.0423\n",
      "step 3500: train loss 1.9032, val loss 2.0347\n",
      "step 4000: train loss 1.8922, val loss 2.0254\n",
      "step 4500: train loss 1.8739, val loss 2.0063\n",
      "step 5000: train loss 1.8666, val loss 2.0013\n",
      "step 5500: train loss 1.8621, val loss 1.9908\n",
      "step 6000: train loss 1.8571, val loss 1.9962\n",
      "step 6500: train loss 1.8476, val loss 1.9818\n",
      "step 7000: train loss 1.8503, val loss 1.9898\n",
      "step 7500: train loss 1.8441, val loss 1.9833\n",
      "step 8000: train loss 1.8430, val loss 1.9803\n",
      "step 8500: train loss 1.8327, val loss 1.9769\n",
      "step 9000: train loss 1.8302, val loss 1.9756\n",
      "step 9500: train loss 1.8259, val loss 1.9763\n",
      "step 10000: train loss 1.8336, val loss 1.9780\n",
      "step 10500: train loss 1.8262, val loss 1.9673\n",
      "step 11000: train loss 1.8238, val loss 1.9638\n",
      "step 11500: train loss 1.8164, val loss 1.9588\n",
      "step 12000: train loss 1.8186, val loss 1.9592\n",
      "step 12500: train loss 1.8130, val loss 1.9637\n",
      "step 13000: train loss 1.8177, val loss 1.9617\n",
      "step 13500: train loss 1.8091, val loss 1.9516\n",
      "step 14000: train loss 1.8072, val loss 1.9566\n",
      "step 14500: train loss 1.8051, val loss 1.9507\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "for iter in tqdm(range(max_iters)):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(m, eval_iters, train_data, val_data, batch_size, block_size)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(train_data, batch_size, block_size)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5f3c05c-7b3c-45c1-a667-7e636b0d6eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "muna o cundo lhenterdo um se\n",
      "suarfre que livro. Elumar volimar estalves o Rumèração e abiluto febaramenos da Rá Raglusão que o sei reparo assofans\n",
      " manhm recandens derias os um coistados \n",
      "compledesão sestur de Sr. Ne a fiúbios\n",
      "por\n",
      "princiavo ctãole e elem le iromigo.\n",
      "\n",
      "Gandinho\n",
      "\n",
      "Tantes o acaríso como fasticunos tinhas semas mes ambaira se é a pretendura. Talbeicato. no a riemadar esta e purós ido escê lemecia que sedorava dos dáros.\n",
      "\n",
      "Que perniarias que tempos aperaçande teres em alte mum um\n",
      "mais m\n"
     ]
    }
   ],
   "source": [
    "#run this cell to check generated text, you can run multiple times and see different text generated\n",
    "\n",
    "print(tokenizer.decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357e7da-46e9-4c3f-9366-d22cfca3cae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
