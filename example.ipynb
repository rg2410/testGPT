{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d16748c-90b8-4f4f-a1fa-a3081eef315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "os.chdir('..\\\\') \n",
    "from testGPT.model import GPTConfig, GPT\n",
    "from testGPT.train import get_batch, estimate_loss\n",
    "from testGPT.data.char_level import CharEncDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ef9006-87e7-4982-a059-0980ae198f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/text/\"\n",
    "\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.pdf\")\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "docs = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d04e00c-e07f-483e-8499-5b9bdb645289",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Camões\"\n",
    "chunks = [x.page_content.split('Luís de Camões')[-1] if 'Glosa' not in x.page_content else x.page_content.split('38. Glosa')[-1] for x in docs ]\n",
    "text = \" \".join(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c082dc4-6e8f-4445-a77b-c4ebf067a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  572017\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482ac144-5241-4f07-82a5-c0055a523381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Canção\n",
      "\n",
      "Fermosa e gentil Dama, quando vejo a testa de ouro e neve, o lindo aspeito, a boca graciosa, o riso honesto, o colo de cristal, o branco peito, de meu não quero mais que meu desejo, nem mais de vós que ver tão lindo gesto. Ali me manifesto por vosso a Deus e ao mundo; ali me inflamo nas lágrimas que choro, e de mim, que vos amo, em ver que soube amar-vos, me namoro; e fico por mim só perdido, de arte que hei ciúmes de mim por vossa parte.\n",
      "\n",
      "Se porventura vivo descontente por fraqueza d'esprito, padecendo a doce pena que entender não sei, fujo de mim e acolho-me, correndo, à vossa vista; e fico tão contente que zombo dos tormentos que passei. De quem me queixarei se vós me dais a vida deste jeito nos males que padeço, senão de meu sujeito,\n",
      "\n",
      "que não cabe com bem de tanto preço? Mas inda isso de mim cuidar não posso, de estar muito soberbo com ser vosso.\n",
      "\n",
      "Se, por algum acerto, Amor vos erra por parte do desejo, cometendo algum nefando e torpe desatino, se ainda mais que ver, e\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37248f5a-26c1-4ce4-bfaf-6fc445a2bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharEncDec(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fddea3-a4b4-4da7-8d80-5ae6203640d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'()*,-./0123456789:;<>?ABCDEFGHIJLMNOPQRSTUVWXYZ[]`abcdefghijlmnopqrstuvwxyz{|}~¡ª«»¿ÀÁÃÇÉÍÓÔÕÜàáâãçèéêëìíïñòóôõùúü–—’\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "print(''.join(tokenizer.chars))\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "599412c7-f12f-4ecd-a29e-3553766ae918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CharEncDec.enconde of <testGPT.data.char_level.CharEncDec object at 0x000001FA183D9B90>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.enconde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d0b0ad-884c-4873-bc22-0558b843ea56",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CharEncDec' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create a mapping from characters to integers\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(text[:\u001b[38;5;241m500\u001b[39m]))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(encode(text[:\u001b[38;5;241m500\u001b[39m])))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CharEncDec' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "\n",
    "print(tokenizer.encode(text[:500]))\n",
    "print(tokenizer.decode(encode(text[:500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7982de-6588-43ce-8a43-29c11e64f1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([572017]) torch.int64\n",
      "tensor([  0,   0,  14,  11,   1,  30,  56,  68, 104, 103,  69,   0,   0,  33,\n",
      "         60,  72,  67,  69,  73,  56,   1,  60,   1,  62,  60,  68,  74,  64,\n",
      "         66,   1,  31,  56,  67,  56,   9,   1,  71,  75,  56,  68,  59,  69,\n",
      "          1,  76,  60,  65,  69,   1,  56,   1,  74,  60,  73,  74,  56,   1,\n",
      "         59,  60,   1,  69,  75,  72,  69,   1,  60,   1,  68,  60,  76,  60,\n",
      "          9,   1,  69,   1,  66,  64,  68,  59,  69,   1,  56,  73,  70,  60,\n",
      "         64,  74,  69,   9,   1,  56,   1,  57,  69,  58,  56,   1,  62,  72,\n",
      "         56,  58,  64,  69,  73,  56,   9,   1,  69,   1,  72,  64,  73,  69,\n",
      "          1,  63,  69,  68,  60,  73,  74,  69,   9,   1,  69,   1,  58,  69,\n",
      "         66,  69,   1,  59,  60,   1,  58,  72,  64,  73,  74,  56,  66,   9,\n",
      "          1,  69,   1,  57,  72,  56,  68,  58,  69,   1,  70,  60,  64,  74,\n",
      "         69,   9,   1,  59,  60,   1,  67,  60,  75,   1,  68, 103,  69,   1,\n",
      "         71,  75,  60,  72,  69,   1,  67,  56,  64,  73,   1,  71,  75,  60,\n",
      "          1,  67,  60,  75,   1,  59,  60,  73,  60,  65,  69,   9,   1,  68,\n",
      "         60,  67,   1,  67,  56,  64,  73,   1,  59,  60,   1,  76, 114,  73,\n",
      "          1,  71,  75,  60,   1,  76,  60,  72,   1,  74, 103,  69,   1,  66,\n",
      "         64,  68,  59,  69,   1,  62,  60,  73,  74,  69,  11,   1,  28,  66,\n",
      "         64,   1,  67,  60,   1,  67,  56,  68,  64,  61,  60,  73,  74,  69,\n",
      "          1,  70,  69,  72,   1,  76,  69,  73,  73,  69,   1,  56,   1,  31,\n",
      "         60,  75,  73,   1,  60,   1,  56,  69,   1,  67,  75,  68,  59,  69,\n",
      "         24,   1,  56,  66,  64,   1,  67,  60,   1,  64,  68,  61,  66,  56,\n",
      "         67,  69,   1,  68,  56,  73,   1,  66, 101,  62,  72,  64,  67,  56,\n",
      "         73,   1,  71,  75,  60,   1,  58,  63,  69,  72,  69,   9,   1,  60,\n",
      "          1,  59,  60,   1,  67,  64,  67,   9,   1,  71,  75,  60,   1,  76,\n",
      "         69,  73,   1,  56,  67,  69,   9,   1,  60,  67,   1,  76,  60,  72,\n",
      "          1,  71,  75,  60,   1,  73,  69,  75,  57,  60,   1,  56,  67,  56,\n",
      "         72,  10,  76,  69,  73,   9,   1,  67,  60,   1,  68,  56,  67,  69,\n",
      "         72,  69,  24,   1,  60,   1,  61,  64,  58,  69,   1,  70,  69,  72,\n",
      "          1,  67,  64,  67,   1,  73, 114,   1,  70,  60,  72,  59,  64,  59,\n",
      "         69,   9,   1,  59,  60,   1,  56,  72,  74,  60,   1,  71,  75,  60,\n",
      "          1,  63,  60,  64,   1,  58,  64, 118,  67,  60,  73,   1,  59,  60,\n",
      "          1,  67,  64,  67,   1,  70,  69,  72,   1,  76,  69,  73,  73,  56,\n",
      "          1,  70,  56,  72,  74,  60,  11,   0,   0,  45,  60,   1,  70,  69,\n",
      "         72,  76,  60,  68,  74,  75,  72,  56,   1,  76,  64,  76,  69,   1,\n",
      "         59,  60,  73,  58,  69,  68,  74,  60,  68,  74,  60,   1,  70,  69,\n",
      "         72,   1,  61,  72,  56,  71,  75,  60,  80,  56])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8168b8-83ae-4499-857c-e0d95d5b3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fbe64ef-214b-4e43-b583-7021f8fe5643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 123])\n",
      "tensor(4.9798, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "á/ostu<U»0|ÜIa' tÉX/wúá~u*GI'3—ô—~G>31Üh»ad{1â32DÍÍ}ÜUtì7v;X&ÃÁ|9ÜMRIX)Ç`fWíFzã63çYwïò`Édfl~6:à«’aw7\n",
      "Num params:  45883\n"
     ]
    }
   ],
   "source": [
    "config = GPTConfig()\n",
    "block_size = 128\n",
    "config.block_size = block_size\n",
    "config.vocab_size = vocab_size\n",
    "config.n_layer = 3\n",
    "config.n_head = 4\n",
    "config.n_embd = 32\n",
    "config.dropout = 0.1\n",
    "\n",
    "\n",
    "batch_size = 32 # how many independent sequences will we process in parallel?\n",
    "max_iters = 200000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 200\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = GPT(config)\n",
    "m = model.to(device)\n",
    "xb, yb = get_batch(train_data, batch_size, block_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))\n",
    "print('Num params: ', m.get_num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6f1479-5791-4987-92ba-0a23b622d1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9597f60adc6f48b1919d96bdae5d30cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.9757, val loss 4.9683\n",
      "step 500: train loss 2.3887, val loss 2.3607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "for iter in tqdm(range(max_iters)):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss(m, eval_iters, train_data, val_data, batch_size, block_size)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(train_data, batch_size, block_size)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5f3c05c-7b3c-45c1-a667-7e636b0d6eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "«Damosos\n",
      "\n",
      "a pralha o que se vejo vós almaros no as dita da gente sebo vas enclta íreros varoveer neliá da Lusitando, Deptundo, Que assi rompanha Elegas a Nunos altos senão ter muitar namado; e, que os tabalha, juyeita estrasse suavar tuemente Desos vossoeles que que quero manha come tonsidadas; E, buscandas, comeno endo que lhamada extrem corra, enteja que crievo quem tinha por poder a Nocerto, e nas como apio dor parço a farra estaráro; se deiente escuro, Inúmonho Senhora no suada, Faras nas, c\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357e7da-46e9-4c3f-9366-d22cfca3cae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
